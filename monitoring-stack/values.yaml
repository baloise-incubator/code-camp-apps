# cluster
clusterName: incubator
responsible: codecamp@baloise.dev
routeDomain: apps.baloise.dev
clusterEnvironment: nonprod
appEnvironment: nonprod
infraCluster: true

# monitoring
enableMonitoring: true
enablespringBootMonitoring: true
clusterMonitoringNamespace: platform-monitoring
alertmanager:
  mailAlerts: false
  teams:
    enabled: false
thanosQuerier:
  enableLocalClusterMonitoring: true
  clusterTargets: {}

# Loki
loki-distributed:
  global:
    dnsService: dns-default
    dnsNamespace: openshift-dns
  loki:
    podSecurityContext:
      fsGroup: 1001050000
      runAsGroup: 1001050000
      runAsUser: 1001050000
    containersecurityContext:
      runAsUser: 1001050000
      runAsGroup: 1001050000
    schemaConfig:
      configs:
      - from: "2020-07-01"
        store: boltdb-shipper
        object_store: aws
        schema: v11
        index:
          prefix: index_
          period: 24h
  # -- Check https://grafana.com/docs/loki/latest/configuration/#storage_config for more info on how to configure storages
    storageConfig:
      aws:
        # full example: http://loki:supersecret@localhost.:9000
        s3: "http://enterprise-logs:supersecret@minio:9000"
        s3forcepathstyle: true
        endpoint: "minio:9000"
        bucketnames: "chunks"
        access_key_id: "Z6pMmr58iXDAKVqelHFe"
        secret_access_key: "uoqRcKpfJX0r2GMbiSrqtwJtNsLifeMhqcCJrEcu"
        insecure: true
      boltdb_shipper:
        active_index_directory: /data/boltdb-shipper-active
        cache_location: /data/boltdb-shipper-cache
        cache_ttl: 24h         # Can be increased for faster performance over longer query periods, uses more disk space
        shared_store: s3
  gateway:
    podSecurityContext:
      fsGroup: 1001050000
      runAsGroup: 1001050000
      runAsUser: 1001050000
    containersecurityContext:
      runAsUser: 1001050000
      runAsGroup: 1001050000
  ingester:
    extraVolumes:
    - name: bolt-db
      emptyDir: {}
    extraVolumeMounts:
    - name: bolt-db
      mountPath: /data
  querier:
    extraVolumes:
    - name: bolt-db
      emptyDir: {}
    extraVolumeMounts:
    - name: bolt-db
      mountPath: /data
# Tempo
tempo-distributed:
  traces:
    otlp:
      grpc:
        enabled: true
  minio:
    enabled: true
    podSecurityContext:
      enabled: false
    securityContext:
      enabled: false
  tempo:
    podSecurityContext:
      fsGroup: 1001050000
    securityContext:
      runAsUser: 1001050000
      runAsGroup: 1001050000

# Pyroscope micro-services
pyroscope:
  pyroscope:
    podSecurityContext:
      fsGroup: 1001050000
    securityContext:
      runAsUser: 1001050000
      runAsGroup: 1001050000
    components:
      querier:
        kind: Deployment
        replicaCount: 3
        resources:
          limits:
            memory: 1Gi
          requests:
            memory: 256Mi
            cpu: 1
      query-frontend:
        kind: Deployment
        replicaCount: 2
        resources:
          limits:
            memory: 1Gi
          requests:
            memory: 256Mi
            cpu: 100m
      query-scheduler:
        kind: Deployment
        replicaCount: 2
        resources:
          limits:
            memory: 1Gi
          requests:
            memory: 256Mi
            cpu: 100m
      distributor:
        kind: Deployment
        replicaCount: 2
        resources:
          limits:
            memory: 1Gi
          requests:
            memory: 256Mi
            cpu: 500m
      ingester:
        kind: StatefulSet
        replicaCount: 3
        terminationGracePeriodSeconds: 600
        resources:
          limits:
            memory: 16Gi
          requests:
            memory: 8Gi
            cpu: 1
      store-gateway:
        kind: StatefulSet
        replicaCount: 3
        persistence:
          # The store-gateway needs not need persistent storage, but we still run it as a StatefulSet
          # This is to avoid having blocks of data being
          enabled: false
        resources:
          limits:
            memory: 16Gi
          requests:
            memory: 8Gi
            cpu: 1
    rbac:
      create: false
    config: |
      storage:
        backend: s3
        s3:
          endpoint: "minio:9000"
          bucket_name: "grafana-pyroscope-data"
          access_key_id: "Z6pMmr58iXDAKVqelHFe"
          secret_access_key: "uoqRcKpfJX0r2GMbiSrqtwJtNsLifeMhqcCJrEcu"
          insecure: true
  agent:
    enabled: false
  minio:
    enabled: false

# jaeger
jaeger:
  tag: 1.46
  collector:
    extraEnv:
      - name: COLLECTOR_OTLP_ENABLED
        value: 'true'
  storage:
    type: elasticsearch
  provisionDataStore:
    cassandra: false
    elasticsearch: true
  elasticsearch:
    sysctlInitContainer:
      enabled: false
    securityContext:
      runAsUser: 1001050000
    podSecurityContext:
      fsGroup: 1001050000
      runAsUser: 1001050000
  hotrod:
    enabled: true
    extraArgs:
      - --otel-exporter=otlp
    extraEnv:
      - name: OTEL_EXPORTER_OTLP_ENDPOINT
        value: http://monitoring-stack-opentelemetry-collector:4318

# OpenTelemetry Collector
opentelemetry-collector:
  mode: deployment
  serviceMonitor:
    enabled: true
    metricsEndpoints:
    - ports: metrics
    - ports: 8889
  config:
    exporters:
      jaeger:
        endpoint: "http://monitoring-stack-jaeger-collector:14250"
        tls:
          insecure: true
      prometheus:
        endpoint: "0.0.0.0:8889"
    processors:
      batch:
      spanmetrics:
        metrics_exporter: prometheus
    receivers:
      otlp:
        protocols:
          http:
            endpoint: "0.0.0.0:4318"
          grpc:
            endpoint: "0.0.0.0:4317"
      otlp/spanmetrics:
        protocols:
          grpc:
            endpoint: "localhost:65535"
    service:
      pipelines:
        traces:
          receivers:
            - otlp
          processors:
            - spanmetrics
            - batch
          exporters:
            - jaeger
        metrics:
          receivers:
            - otlp/spanmetrics
          processors:
            - batch
          exporters:
            - prometheus

#Promtail
promtail:
  config:
    clients:
      - url: http://monitoring-stack-loki-distributed-distributor.monitoring-stack.svc:3100/loki/api/v1/push
    positions:
      filename: "/tmp/promtail/positions.yaml"
  extraVolumes:
    - name: posit
      emptyDir: {}
  extraVolumeMounts:
    - name: posit
      mountPath: "/tmp/promtail"
  rbac:
    create: false
  podSecurityContext:
    privileged: true
  containerSecurityContext:
    privileged: true
